{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cols = ['reactivity', 'deg_Mg_pH10', 'deg_Mg_50C', 'deg_pH10', 'deg_50C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cols = ['sequence', 'structure', 'predicted_loop_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json('train.json', lines=True)\n",
    "test = pd.read_json('test.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.query(\"signal_to_noise >= 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.query(\"SN_filter == 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_private = test.query(\"seq_length == 130\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_public = test.query(\"seq_length == 107\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_inputs(df,input_cols):\n",
    "    \"\"\"\n",
    "    Converts inputs into one-hot\n",
    "    \"\"\"\n",
    "    output = []\n",
    "    for i in range(len(input_cols)):\n",
    "        tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n",
    "        tokenizer.fit_on_texts(np.asarray(df[input_cols[i]]))\n",
    "        tmp = tokenizer.texts_to_sequences(np.asarray(df[input_cols[i]]))\n",
    "        output.append(np.asarray(keras.utils.to_categorical(tmp)[:,:,1:]))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = preprocess_inputs(train,input_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1587"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_inputs(inputs, length):\n",
    "    \"\"\"\n",
    "    Merges the one-hot inputs by columns\n",
    "    Also snips seq length's till desired amount\n",
    "    \"\"\"\n",
    "    size = len(inputs[0])\n",
    "    output = []\n",
    "    for i in range(size):\n",
    "        output.append(np.concatenate((inputs[0][i][0:length], inputs[1][i][0:length], inputs[2][i][0:length]), axis = 1))\n",
    "    return np.asarray(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_simple = merge_inputs(inputs, 68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1587, 68, 14)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_simple.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = np.zeros((2,5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1[1,1,0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_results(df, results):\n",
    "    \"\"\"\n",
    "    Makes sure that the results are in the appropriate format:\n",
    "        [layers,lines,columns] in an np array\n",
    "    \"\"\"\n",
    "    tmp = np.asarray(df[results])\n",
    "    size = len(tmp[0])\n",
    "    output = np.zeros((len(tmp),len(tmp[0][0]),len(results)))\n",
    "    for i in range(len(results)):\n",
    "        for j in range(size):\n",
    "            tmp[i,j] = np.asarray(tmp[i,j])\n",
    "    for i in range(len(tmp)):\n",
    "        output[i] = np.vstack((tmp[i,0], tmp[i,1], tmp[i,2], \n",
    "                                tmp[i,3], tmp[i,4]))[:,:].T\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_results = preprocess_results(train, pred_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1587, 68, 5)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3297, 0.7556, 0.3581, 2.3375, 0.6382])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_results[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, None, 10)          430       \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                336       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                170       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 68)                748       \n",
      "=================================================================\n",
      "Total params: 1,904\n",
      "Trainable params: 1,904\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_simple = keras.Sequential()\n",
    "\n",
    "model_simple.add(keras.layers.Conv1D(filters=10, kernel_size=3, activation=('relu'), \n",
    "                                     input_shape=(None,14), padding='same'))\n",
    "model_simple.add(keras.layers.GlobalMaxPooling1D())\n",
    "model_simple.add(keras.layers.Dense(20, activation=('relu')))\n",
    "model_simple.add(keras.layers.Dense(16, activation='relu'))\n",
    "model_simple.add(keras.layers.Dropout(rate=0.4))\n",
    "model_simple.add(keras.layers.Dense(10, activation='relu'))\n",
    "\n",
    "\n",
    "#Est-ce que le out put c'est 3 valuers distinctes, ou 1 valeurs mais qui existe dans 3 channels?\n",
    "model_simple.add(keras.layers.Dense(68, activation='linear'))\n",
    "\n",
    "# mean_squared_error car on a affair a une regression\n",
    "model_simple.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
    "model_simple.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1269 samples, validate on 318 samples\n",
      "Epoch 1/100\n",
      "1269/1269 [==============================] - 2s 1ms/step - loss: 0.3404 - mean_squared_error: 0.3404 - val_loss: 0.3214 - val_mean_squared_error: 0.3214\n",
      "Epoch 2/100\n",
      "1269/1269 [==============================] - 0s 347us/step - loss: 0.3030 - mean_squared_error: 0.3030 - val_loss: 0.2796 - val_mean_squared_error: 0.2796\n",
      "Epoch 3/100\n",
      "1269/1269 [==============================] - 0s 331us/step - loss: 0.2669 - mean_squared_error: 0.2669 - val_loss: 0.2390 - val_mean_squared_error: 0.2390\n",
      "Epoch 4/100\n",
      "1269/1269 [==============================] - 0s 260us/step - loss: 0.2340 - mean_squared_error: 0.2340 - val_loss: 0.2079 - val_mean_squared_error: 0.2079\n",
      "Epoch 5/100\n",
      "1269/1269 [==============================] - 0s 244us/step - loss: 0.2101 - mean_squared_error: 0.2101 - val_loss: 0.1887 - val_mean_squared_error: 0.1887\n",
      "Epoch 6/100\n",
      "1269/1269 [==============================] - 0s 268us/step - loss: 0.1952 - mean_squared_error: 0.1952 - val_loss: 0.1794 - val_mean_squared_error: 0.1794\n",
      "Epoch 7/100\n",
      "1269/1269 [==============================] - 0s 268us/step - loss: 0.1851 - mean_squared_error: 0.1851 - val_loss: 0.1740 - val_mean_squared_error: 0.1740\n",
      "Epoch 8/100\n",
      "1269/1269 [==============================] - 0s 252us/step - loss: 0.1804 - mean_squared_error: 0.1804 - val_loss: 0.1697 - val_mean_squared_error: 0.1697\n",
      "Epoch 9/100\n",
      "1269/1269 [==============================] - 0s 252us/step - loss: 0.1780 - mean_squared_error: 0.1780 - val_loss: 0.1675 - val_mean_squared_error: 0.1675\n",
      "Epoch 10/100\n",
      "1269/1269 [==============================] - 0s 268us/step - loss: 0.1729 - mean_squared_error: 0.1729 - val_loss: 0.1676 - val_mean_squared_error: 0.1676\n",
      "Epoch 11/100\n",
      "1269/1269 [==============================] - 0s 260us/step - loss: 0.1727 - mean_squared_error: 0.1727 - val_loss: 0.1672 - val_mean_squared_error: 0.1672\n",
      "Epoch 12/100\n",
      "1269/1269 [==============================] - 0s 268us/step - loss: 0.1706 - mean_squared_error: 0.1706 - val_loss: 0.1673 - val_mean_squared_error: 0.1673\n",
      "Epoch 13/100\n",
      "1269/1269 [==============================] - 0s 268us/step - loss: 0.1690 - mean_squared_error: 0.1690 - val_loss: 0.1666 - val_mean_squared_error: 0.1666\n",
      "Epoch 14/100\n",
      "1269/1269 [==============================] - 0s 252us/step - loss: 0.1672 - mean_squared_error: 0.1672 - val_loss: 0.1659 - val_mean_squared_error: 0.1659\n",
      "Epoch 15/100\n",
      "1269/1269 [==============================] - 0s 284us/step - loss: 0.1666 - mean_squared_error: 0.1666 - val_loss: 0.1659 - val_mean_squared_error: 0.1659\n",
      "Epoch 16/100\n",
      "1269/1269 [==============================] - 0s 260us/step - loss: 0.1661 - mean_squared_error: 0.1661 - val_loss: 0.1659 - val_mean_squared_error: 0.1659\n",
      "Epoch 17/100\n",
      "1269/1269 [==============================] - 0s 252us/step - loss: 0.1649 - mean_squared_error: 0.1649 - val_loss: 0.1662 - val_mean_squared_error: 0.1662\n",
      "Epoch 18/100\n",
      "1269/1269 [==============================] - 0s 260us/step - loss: 0.1643 - mean_squared_error: 0.1643 - val_loss: 0.1659 - val_mean_squared_error: 0.1659\n",
      "Epoch 19/100\n",
      "1269/1269 [==============================] - 0s 260us/step - loss: 0.1638 - mean_squared_error: 0.1638 - val_loss: 0.1657 - val_mean_squared_error: 0.1657\n",
      "Epoch 20/100\n",
      "1269/1269 [==============================] - 0s 252us/step - loss: 0.1625 - mean_squared_error: 0.1625 - val_loss: 0.1647 - val_mean_squared_error: 0.1647\n",
      "Epoch 21/100\n",
      "1269/1269 [==============================] - 0s 252us/step - loss: 0.1620 - mean_squared_error: 0.1620 - val_loss: 0.1645 - val_mean_squared_error: 0.1645\n",
      "Epoch 22/100\n",
      "1269/1269 [==============================] - 0s 252us/step - loss: 0.1618 - mean_squared_error: 0.1618 - val_loss: 0.1641 - val_mean_squared_error: 0.1641\n",
      "Epoch 23/100\n",
      "1269/1269 [==============================] - 0s 252us/step - loss: 0.1611 - mean_squared_error: 0.1611 - val_loss: 0.1642 - val_mean_squared_error: 0.1642\n",
      "Epoch 24/100\n",
      "1269/1269 [==============================] - 0s 260us/step - loss: 0.1608 - mean_squared_error: 0.1608 - val_loss: 0.1645 - val_mean_squared_error: 0.1645\n",
      "Epoch 25/100\n",
      "1269/1269 [==============================] - 0s 244us/step - loss: 0.1603 - mean_squared_error: 0.1603 - val_loss: 0.1642 - val_mean_squared_error: 0.1642\n",
      "Epoch 26/100\n",
      "1269/1269 [==============================] - 0s 260us/step - loss: 0.1600 - mean_squared_error: 0.1600 - val_loss: 0.1638 - val_mean_squared_error: 0.1638\n",
      "Epoch 27/100\n",
      "1269/1269 [==============================] - 0s 244us/step - loss: 0.1599 - mean_squared_error: 0.1599 - val_loss: 0.1648 - val_mean_squared_error: 0.1648\n",
      "Epoch 28/100\n",
      "1269/1269 [==============================] - 0s 252us/step - loss: 0.1597 - mean_squared_error: 0.1597 - val_loss: 0.1652 - val_mean_squared_error: 0.1652\n",
      "Epoch 29/100\n",
      "1269/1269 [==============================] - 0s 260us/step - loss: 0.1597 - mean_squared_error: 0.1597 - val_loss: 0.1637 - val_mean_squared_error: 0.1637\n",
      "Epoch 30/100\n",
      "1269/1269 [==============================] - 0s 252us/step - loss: 0.1592 - mean_squared_error: 0.1592 - val_loss: 0.1636 - val_mean_squared_error: 0.1636\n",
      "Epoch 31/100\n",
      "1269/1269 [==============================] - 0s 260us/step - loss: 0.1593 - mean_squared_error: 0.1593 - val_loss: 0.1635 - val_mean_squared_error: 0.1635\n",
      "Epoch 32/100\n",
      "1269/1269 [==============================] - 0s 252us/step - loss: 0.1591 - mean_squared_error: 0.1591 - val_loss: 0.1632 - val_mean_squared_error: 0.1632\n",
      "Epoch 33/100\n",
      "1269/1269 [==============================] - 0s 252us/step - loss: 0.1590 - mean_squared_error: 0.1590 - val_loss: 0.1633 - val_mean_squared_error: 0.1633\n",
      "Epoch 34/100\n",
      "1269/1269 [==============================] - 0s 252us/step - loss: 0.1585 - mean_squared_error: 0.1585 - val_loss: 0.1629 - val_mean_squared_error: 0.1629\n",
      "Epoch 35/100\n",
      "1269/1269 [==============================] - 0s 260us/step - loss: 0.1588 - mean_squared_error: 0.1588 - val_loss: 0.1628 - val_mean_squared_error: 0.1628\n",
      "Epoch 36/100\n",
      "1269/1269 [==============================] - 0s 252us/step - loss: 0.1586 - mean_squared_error: 0.1586 - val_loss: 0.1629 - val_mean_squared_error: 0.1629\n",
      "Epoch 37/100\n",
      "1269/1269 [==============================] - 0s 252us/step - loss: 0.1586 - mean_squared_error: 0.1586 - val_loss: 0.1631 - val_mean_squared_error: 0.1631\n",
      "Epoch 38/100\n",
      "1269/1269 [==============================] - 0s 260us/step - loss: 0.1583 - mean_squared_error: 0.1583 - val_loss: 0.1627 - val_mean_squared_error: 0.1627\n",
      "Epoch 39/100\n",
      "1269/1269 [==============================] - 0s 252us/step - loss: 0.1583 - mean_squared_error: 0.1583 - val_loss: 0.1627 - val_mean_squared_error: 0.1627\n",
      "Epoch 40/100\n",
      "1269/1269 [==============================] - 0s 323us/step - loss: 0.1583 - mean_squared_error: 0.1583 - val_loss: 0.1627 - val_mean_squared_error: 0.1627\n",
      "Epoch 41/100\n",
      "1269/1269 [==============================] - 0s 292us/step - loss: 0.1581 - mean_squared_error: 0.1581 - val_loss: 0.1626 - val_mean_squared_error: 0.1626\n",
      "Epoch 42/100\n",
      "1269/1269 [==============================] - 0s 292us/step - loss: 0.1582 - mean_squared_error: 0.1582 - val_loss: 0.1623 - val_mean_squared_error: 0.1623\n",
      "Epoch 43/100\n",
      "1269/1269 [==============================] - 0s 260us/step - loss: 0.1580 - mean_squared_error: 0.1580 - val_loss: 0.1629 - val_mean_squared_error: 0.1629\n",
      "Epoch 44/100\n",
      "1269/1269 [==============================] - 0s 260us/step - loss: 0.1574 - mean_squared_error: 0.1574 - val_loss: 0.1624 - val_mean_squared_error: 0.1624\n",
      "Epoch 45/100\n",
      "1269/1269 [==============================] - 0s 244us/step - loss: 0.1577 - mean_squared_error: 0.1577 - val_loss: 0.1625 - val_mean_squared_error: 0.1625\n",
      "Epoch 46/100\n",
      "1269/1269 [==============================] - 0s 252us/step - loss: 0.1574 - mean_squared_error: 0.1574 - val_loss: 0.1621 - val_mean_squared_error: 0.1621\n",
      "Epoch 47/100\n",
      "1269/1269 [==============================] - 0s 323us/step - loss: 0.1572 - mean_squared_error: 0.1572 - val_loss: 0.1618 - val_mean_squared_error: 0.1618\n",
      "Epoch 48/100\n",
      "1269/1269 [==============================] - 0s 386us/step - loss: 0.1574 - mean_squared_error: 0.1574 - val_loss: 0.1622 - val_mean_squared_error: 0.1622\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1269/1269 [==============================] - 0s 347us/step - loss: 0.1573 - mean_squared_error: 0.1573 - val_loss: 0.1621 - val_mean_squared_error: 0.1621\n",
      "Epoch 50/100\n",
      "1269/1269 [==============================] - 0s 299us/step - loss: 0.1570 - mean_squared_error: 0.1570 - val_loss: 0.1615 - val_mean_squared_error: 0.1615\n",
      "Epoch 51/100\n",
      "1269/1269 [==============================] - 0s 276us/step - loss: 0.1568 - mean_squared_error: 0.1568 - val_loss: 0.1612 - val_mean_squared_error: 0.1612\n",
      "Epoch 52/100\n",
      "1269/1269 [==============================] - 0s 236us/step - loss: 0.1565 - mean_squared_error: 0.1565 - val_loss: 0.1616 - val_mean_squared_error: 0.1616\n",
      "Epoch 53/100\n",
      "1269/1269 [==============================] - 0s 236us/step - loss: 0.1564 - mean_squared_error: 0.1564 - val_loss: 0.1609 - val_mean_squared_error: 0.1609\n",
      "Epoch 54/100\n",
      "1269/1269 [==============================] - 0s 236us/step - loss: 0.1560 - mean_squared_error: 0.1560 - val_loss: 0.1610 - val_mean_squared_error: 0.1610\n",
      "Epoch 55/100\n",
      "1269/1269 [==============================] - 0s 236us/step - loss: 0.1563 - mean_squared_error: 0.1563 - val_loss: 0.1608 - val_mean_squared_error: 0.1608\n",
      "Epoch 56/100\n",
      "1269/1269 [==============================] - 0s 236us/step - loss: 0.1557 - mean_squared_error: 0.1557 - val_loss: 0.1603 - val_mean_squared_error: 0.1603\n",
      "Epoch 57/100\n",
      "1269/1269 [==============================] - 0s 276us/step - loss: 0.1561 - mean_squared_error: 0.1561 - val_loss: 0.1604 - val_mean_squared_error: 0.1604\n",
      "Epoch 58/100\n",
      "1269/1269 [==============================] - 0s 236us/step - loss: 0.1554 - mean_squared_error: 0.1554 - val_loss: 0.1604 - val_mean_squared_error: 0.1604\n",
      "Epoch 59/100\n",
      "1269/1269 [==============================] - 0s 236us/step - loss: 0.1554 - mean_squared_error: 0.1554 - val_loss: 0.1598 - val_mean_squared_error: 0.1598\n",
      "Epoch 60/100\n",
      "1269/1269 [==============================] - 0s 229us/step - loss: 0.1552 - mean_squared_error: 0.1552 - val_loss: 0.1604 - val_mean_squared_error: 0.1604\n",
      "Epoch 61/100\n",
      "1269/1269 [==============================] - 0s 236us/step - loss: 0.1552 - mean_squared_error: 0.1552 - val_loss: 0.1601 - val_mean_squared_error: 0.1601\n",
      "Epoch 62/100\n",
      "1269/1269 [==============================] - 0s 252us/step - loss: 0.1550 - mean_squared_error: 0.1550 - val_loss: 0.1591 - val_mean_squared_error: 0.1591\n",
      "Epoch 63/100\n",
      "1269/1269 [==============================] - 0s 276us/step - loss: 0.1546 - mean_squared_error: 0.1546 - val_loss: 0.1586 - val_mean_squared_error: 0.1586\n",
      "Epoch 64/100\n",
      "1269/1269 [==============================] - 0s 276us/step - loss: 0.1545 - mean_squared_error: 0.1545 - val_loss: 0.1588 - val_mean_squared_error: 0.1588\n",
      "Epoch 65/100\n",
      "1269/1269 [==============================] - 0s 252us/step - loss: 0.1541 - mean_squared_error: 0.1541 - val_loss: 0.1592 - val_mean_squared_error: 0.1592\n",
      "Epoch 66/100\n",
      "1269/1269 [==============================] - 0s 244us/step - loss: 0.1542 - mean_squared_error: 0.1542 - val_loss: 0.1582 - val_mean_squared_error: 0.1582\n",
      "Epoch 67/100\n",
      "1269/1269 [==============================] - 0s 252us/step - loss: 0.1535 - mean_squared_error: 0.1535 - val_loss: 0.1583 - val_mean_squared_error: 0.1583\n",
      "Epoch 68/100\n",
      "1269/1269 [==============================] - 0s 260us/step - loss: 0.1535 - mean_squared_error: 0.1535 - val_loss: 0.1583 - val_mean_squared_error: 0.1583\n",
      "Epoch 69/100\n",
      "1269/1269 [==============================] - 0s 244us/step - loss: 0.1539 - mean_squared_error: 0.1539 - val_loss: 0.1582 - val_mean_squared_error: 0.1582\n",
      "Epoch 70/100\n",
      "1269/1269 [==============================] - 0s 244us/step - loss: 0.1532 - mean_squared_error: 0.1532 - val_loss: 0.1584 - val_mean_squared_error: 0.1584\n",
      "Epoch 71/100\n",
      "1269/1269 [==============================] - 0s 244us/step - loss: 0.1536 - mean_squared_error: 0.1536 - val_loss: 0.1580 - val_mean_squared_error: 0.1580\n",
      "Epoch 72/100\n",
      "1269/1269 [==============================] - 0s 236us/step - loss: 0.1532 - mean_squared_error: 0.1532 - val_loss: 0.1576 - val_mean_squared_error: 0.1576\n",
      "Epoch 73/100\n",
      "1269/1269 [==============================] - 0s 252us/step - loss: 0.1531 - mean_squared_error: 0.1531 - val_loss: 0.1572 - val_mean_squared_error: 0.1572\n",
      "Epoch 74/100\n",
      "1269/1269 [==============================] - 0s 276us/step - loss: 0.1532 - mean_squared_error: 0.1532 - val_loss: 0.1575 - val_mean_squared_error: 0.1575\n",
      "Epoch 75/100\n",
      "1269/1269 [==============================] - 0s 276us/step - loss: 0.1531 - mean_squared_error: 0.1531 - val_loss: 0.1578 - val_mean_squared_error: 0.1578\n",
      "Epoch 76/100\n",
      "1269/1269 [==============================] - 0s 244us/step - loss: 0.1529 - mean_squared_error: 0.1529 - val_loss: 0.1577 - val_mean_squared_error: 0.1577\n",
      "Epoch 77/100\n",
      "1269/1269 [==============================] - 0s 244us/step - loss: 0.1527 - mean_squared_error: 0.1527 - val_loss: 0.1574 - val_mean_squared_error: 0.1574\n",
      "Epoch 78/100\n",
      "1269/1269 [==============================] - 0s 244us/step - loss: 0.1528 - mean_squared_error: 0.1528 - val_loss: 0.1571 - val_mean_squared_error: 0.1571\n",
      "Epoch 79/100\n",
      "1269/1269 [==============================] - 0s 252us/step - loss: 0.1528 - mean_squared_error: 0.1528 - val_loss: 0.1576 - val_mean_squared_error: 0.1576\n",
      "Epoch 80/100\n",
      "1269/1269 [==============================] - 0s 268us/step - loss: 0.1522 - mean_squared_error: 0.1522 - val_loss: 0.1577 - val_mean_squared_error: 0.1577\n",
      "Epoch 81/100\n",
      "1269/1269 [==============================] - 0s 244us/step - loss: 0.1523 - mean_squared_error: 0.1523 - val_loss: 0.1571 - val_mean_squared_error: 0.1571\n",
      "Epoch 82/100\n",
      "1269/1269 [==============================] - 0s 260us/step - loss: 0.1526 - mean_squared_error: 0.1526 - val_loss: 0.1570 - val_mean_squared_error: 0.1570\n",
      "Epoch 83/100\n",
      "1269/1269 [==============================] - 0s 276us/step - loss: 0.1522 - mean_squared_error: 0.1522 - val_loss: 0.1573 - val_mean_squared_error: 0.1573\n",
      "Epoch 84/100\n",
      "1269/1269 [==============================] - 0s 252us/step - loss: 0.1518 - mean_squared_error: 0.1518 - val_loss: 0.1569 - val_mean_squared_error: 0.1569\n",
      "Epoch 85/100\n",
      "1269/1269 [==============================] - 0s 299us/step - loss: 0.1521 - mean_squared_error: 0.1521 - val_loss: 0.1576 - val_mean_squared_error: 0.1576\n",
      "Epoch 86/100\n",
      "1269/1269 [==============================] - 0s 260us/step - loss: 0.1516 - mean_squared_error: 0.1516 - val_loss: 0.1568 - val_mean_squared_error: 0.1568\n",
      "Epoch 87/100\n",
      "1269/1269 [==============================] - 0s 252us/step - loss: 0.1518 - mean_squared_error: 0.1518 - val_loss: 0.1565 - val_mean_squared_error: 0.1565\n",
      "Epoch 88/100\n",
      "1269/1269 [==============================] - 0s 331us/step - loss: 0.1515 - mean_squared_error: 0.1515 - val_loss: 0.1568 - val_mean_squared_error: 0.1568\n",
      "Epoch 89/100\n",
      "1269/1269 [==============================] - 0s 378us/step - loss: 0.1516 - mean_squared_error: 0.1516 - val_loss: 0.1571 - val_mean_squared_error: 0.1571\n",
      "Epoch 90/100\n",
      "1269/1269 [==============================] - 0s 331us/step - loss: 0.1516 - mean_squared_error: 0.1516 - val_loss: 0.1573 - val_mean_squared_error: 0.1573\n",
      "Epoch 91/100\n",
      "1269/1269 [==============================] - 0s 307us/step - loss: 0.1517 - mean_squared_error: 0.1517 - val_loss: 0.1569 - val_mean_squared_error: 0.1569\n",
      "Epoch 92/100\n",
      "1269/1269 [==============================] - 0s 315us/step - loss: 0.1513 - mean_squared_error: 0.1513 - val_loss: 0.1564 - val_mean_squared_error: 0.1564\n",
      "Epoch 93/100\n",
      "1269/1269 [==============================] - 0s 292us/step - loss: 0.1513 - mean_squared_error: 0.1513 - val_loss: 0.1562 - val_mean_squared_error: 0.1562\n",
      "Epoch 94/100\n",
      "1269/1269 [==============================] - 1s 473us/step - loss: 0.1510 - mean_squared_error: 0.1510 - val_loss: 0.1562 - val_mean_squared_error: 0.1562\n",
      "Epoch 95/100\n",
      "1269/1269 [==============================] - 1s 490us/step - loss: 0.1514 - mean_squared_error: 0.1514 - val_loss: 0.1563 - val_mean_squared_error: 0.1563\n",
      "Epoch 96/100\n",
      "1269/1269 [==============================] - 1s 441us/step - loss: 0.1512 - mean_squared_error: 0.1512 - val_loss: 0.1570 - val_mean_squared_error: 0.1570\n",
      "Epoch 97/100\n",
      "1269/1269 [==============================] - 0s 355us/step - loss: 0.1508 - mean_squared_error: 0.1508 - val_loss: 0.1566 - val_mean_squared_error: 0.1566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/100\n",
      "1269/1269 [==============================] - 0s 284us/step - loss: 0.1511 - mean_squared_error: 0.1511 - val_loss: 0.1562 - val_mean_squared_error: 0.1562\n",
      "Epoch 99/100\n",
      "1269/1269 [==============================] - 0s 236us/step - loss: 0.1510 - mean_squared_error: 0.1510 - val_loss: 0.1562 - val_mean_squared_error: 0.1562\n",
      "Epoch 100/100\n",
      "1269/1269 [==============================] - 0s 244us/step - loss: 0.1508 - mean_squared_error: 0.1508 - val_loss: 0.1563 - val_mean_squared_error: 0.1563\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xd4d0e80>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_simple.fit(inputs_simple[:], expected_results[:,:,0], batch_size=64, \n",
    "                 epochs=100, verbose=1, validation_split=0.2) # validation loss keeps going down?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49903202, 1.3673505 , 1.0804473 , ..., 0.3443737 , 0.30548564,\n",
       "        0.2879229 ],\n",
       "       [0.46239996, 1.2894375 , 1.1232172 , ..., 0.4509542 , 0.3730848 ,\n",
       "        0.29419088],\n",
       "       [0.46583292, 1.242483  , 0.95405495, ..., 0.29894933, 0.26896116,\n",
       "        0.27414298],\n",
       "       ...,\n",
       "       [0.55453503, 1.6591792 , 1.3614894 , ..., 0.47080028, 0.415768  ,\n",
       "        0.3062266 ],\n",
       "       [0.3492043 , 0.9457277 , 0.8343984 , ..., 0.3986888 , 0.2997829 ,\n",
       "        0.29006147],\n",
       "       [0.5204314 , 1.3829736 , 0.9764974 , ..., 0.23767503, 0.24073514,\n",
       "        0.26185977]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_simple.predict(inputs_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_simple_test_public = preprocess_inputs(test_public,input_cols)\n",
    "inputs_simple_test_public = merge_inputs(inputs_simple_test_public, len(inputs_simple_test_public[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(629, 107, 14)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_simple_test_public.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.43536642, 1.1760983 , 1.0193015 , ..., 0.39466888, 0.3210688 ,\n",
       "        0.28773066],\n",
       "       [0.4054707 , 1.1344357 , 1.0132607 , ..., 0.4402719 , 0.35577345,\n",
       "        0.29849964],\n",
       "       [0.3997292 , 1.088759  , 0.99809575, ..., 0.4348591 , 0.33852947,\n",
       "        0.2902928 ],\n",
       "       ...,\n",
       "       [0.42186713, 1.1826756 , 1.0807523 , ..., 0.47631603, 0.37483597,\n",
       "        0.29756004],\n",
       "       [0.4412241 , 1.2346762 , 1.093946  , ..., 0.44991648, 0.3658199 ,\n",
       "        0.2966246 ],\n",
       "       [0.42913425, 1.1476092 , 0.9673294 , ..., 0.36187583, 0.29775298,\n",
       "        0.2868853 ]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_simple.predict(inputs_simple_test_public)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.3297,  1.5693,  1.1227, ...,  0.2937,  0.2362,  0.5731],\n",
       "       [ 0.4482,  1.4822,  1.1819, ...,  0.6449,  0.04  ,  0.5446],\n",
       "       [ 0.7642,  1.6641,  1.0622, ...,  0.1107,  0.2261,  0.3238],\n",
       "       ...,\n",
       "       [ 0.6957,  1.251 ,  1.3236, ..., -0.0043,  0.0521,  0.0874],\n",
       "       [ 0.2891,  0.4496,  0.7165, ...,  0.8738,  0.2816,  0.554 ],\n",
       "       [ 1.0102,  1.7928,  1.9228, ...,  0.0381, -0.0066,  0.0706]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_results[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "seq (InputLayer)                (None, None, 4)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pair (InputLayer)               (None, None, 3)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "loop (InputLayer)               (None, None, 7)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, None, 10)     130         seq[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, None, 10)     100         pair[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, None, 10)     220         loop[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_4 (GlobalM (None, 10)           0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_5 (GlobalM (None, 10)           0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_6 (GlobalM (None, 10)           0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 20)           220         global_max_pooling1d_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 20)           220         global_max_pooling1d_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 20)           220         global_max_pooling1d_6[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 60)           0           dense_16[0][0]                   \n",
      "                                                                 dense_17[0][0]                   \n",
      "                                                                 dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 60)           0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reactivity (Dense)              (None, 68)           4148        flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "deg_Mg_pH10 (Dense)             (None, 68)           4148        flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "deg_Mg_50C (Dense)              (None, 68)           4148        flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "deg_pH10 (Dense)                (None, 68)           4148        flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "deg_50C (Dense)                 (None, 68)           4148        flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 21,850\n",
      "Trainable params: 21,850\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq_input = keras.layers.Input(shape=(None,4), name=\"seq\")      #Input shape a revoir\n",
    "pair_input = keras.layers.Input(shape=(None,3), name=\"pair\")  \n",
    "loop_input = keras.layers.Input(shape=(None,7), name=\"loop\")  \n",
    "\n",
    "seq_features = keras.layers.Conv1D(filters=10, kernel_size=3, activation=('relu'), \n",
    "                                     padding='same')(seq_input)\n",
    "pair_features = keras.layers.Conv1D(filters=10, kernel_size=3, activation=('relu'), \n",
    "                                     padding='same')(pair_input)\n",
    "loop_features = keras.layers.Conv1D(filters=10, kernel_size=3, activation=('relu'), \n",
    "                                     padding='same')(loop_input)\n",
    "\n",
    "seq_features = keras.layers.GlobalMaxPooling1D()(seq_features)\n",
    "pair_features = keras.layers.GlobalMaxPooling1D()(pair_features)\n",
    "loop_features = keras.layers.GlobalMaxPooling1D()(loop_features)\n",
    "\n",
    "seq_features = keras.layers.Dense(20)(seq_features)\n",
    "pair_features = keras.layers.Dense(20)(pair_features)\n",
    "loop_features = keras.layers.Dense(20)(loop_features)\n",
    "\n",
    "\n",
    "# Merge les features\n",
    "x = keras.layers.concatenate([seq_features, pair_features, loop_features])\n",
    "\n",
    "flat = keras.layers.Flatten()(x)\n",
    "\n",
    "first_pred = keras.layers.Dense(68, name=\"reactivity\")(flat) #regression pour \"reactivity\"\n",
    "second_pred = keras.layers.Dense(68, name=\"deg_Mg_pH10\")(flat)  #regression pour \"ph\"\n",
    "third_pred = keras.layers.Dense(68, name=\"deg_Mg_50C\")(flat)\n",
    "fourth_pred = keras.layers.Dense(68, name=\"deg_pH10\")(flat)\n",
    "fifth_pred = keras.layers.Dense(68, name=\"deg_50C\")(flat)\n",
    "\n",
    "\n",
    "model = keras.Model(\n",
    "    inputs=[seq_input, pair_input, loop_input],\n",
    "    outputs=[first_pred, second_pred, third_pred, fourth_pred, fifth_pred],\n",
    ")\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1269 samples, validate on 318 samples\n",
      "Epoch 1/30\n",
      "1269/1269 [==============================] - 4s 3ms/step - loss: 1.5829 - reactivity_loss: 0.3114 - deg_Mg_pH10_loss: 0.3016 - deg_Mg_50C_loss: 0.3010 - deg_pH10_loss: 0.3943 - deg_50C_loss: 0.2745 - reactivity_mean_squared_error: 0.3114 - deg_Mg_pH10_mean_squared_error: 0.3016 - deg_Mg_50C_mean_squared_error: 0.3010 - deg_pH10_mean_squared_error: 0.3943 - deg_50C_mean_squared_error: 0.2745 - val_loss: 0.9488 - val_reactivity_loss: 0.1828 - val_deg_Mg_pH10_loss: 0.2169 - val_deg_Mg_50C_loss: 0.1823 - val_deg_pH10_loss: 0.2213 - val_deg_50C_loss: 0.1457 - val_reactivity_mean_squared_error: 0.1828 - val_deg_Mg_pH10_mean_squared_error: 0.2169 - val_deg_Mg_50C_mean_squared_error: 0.1823 - val_deg_pH10_mean_squared_error: 0.2213 - val_deg_50C_mean_squared_error: 0.1457\n",
      "Epoch 2/30\n",
      "1269/1269 [==============================] - 1s 630us/step - loss: 0.8685 - reactivity_loss: 0.1686 - deg_Mg_pH10_loss: 0.2127 - deg_Mg_50C_loss: 0.1769 - deg_pH10_loss: 0.1777 - deg_50C_loss: 0.1326 - reactivity_mean_squared_error: 0.1686 - deg_Mg_pH10_mean_squared_error: 0.2127 - deg_Mg_50C_mean_squared_error: 0.1769 - deg_pH10_mean_squared_error: 0.1777 - deg_50C_mean_squared_error: 0.1326 - val_loss: 0.8415 - val_reactivity_loss: 0.1675 - val_deg_Mg_pH10_loss: 0.2119 - val_deg_Mg_50C_loss: 0.1725 - val_deg_pH10_loss: 0.1586 - val_deg_50C_loss: 0.1309 - val_reactivity_mean_squared_error: 0.1675 - val_deg_Mg_pH10_mean_squared_error: 0.2119 - val_deg_Mg_50C_mean_squared_error: 0.1725 - val_deg_pH10_mean_squared_error: 0.1586 - val_deg_50C_mean_squared_error: 0.1309\n",
      "Epoch 3/30\n",
      "1269/1269 [==============================] - 1s 796us/step - loss: 0.8329 - reactivity_loss: 0.1642 - deg_Mg_pH10_loss: 0.2107 - deg_Mg_50C_loss: 0.1734 - deg_pH10_loss: 0.1564 - deg_50C_loss: 0.1282 - reactivity_mean_squared_error: 0.1642 - deg_Mg_pH10_mean_squared_error: 0.2107 - deg_Mg_50C_mean_squared_error: 0.1734 - deg_pH10_mean_squared_error: 0.1564 - deg_50C_mean_squared_error: 0.1282 - val_loss: 0.8339 - val_reactivity_loss: 0.1668 - val_deg_Mg_pH10_loss: 0.2111 - val_deg_Mg_50C_loss: 0.1714 - val_deg_pH10_loss: 0.1553 - val_deg_50C_loss: 0.1293 - val_reactivity_mean_squared_error: 0.1668 - val_deg_Mg_pH10_mean_squared_error: 0.2111 - val_deg_Mg_50C_mean_squared_error: 0.1714 - val_deg_pH10_mean_squared_error: 0.1553 - val_deg_50C_mean_squared_error: 0.1293\n",
      "Epoch 4/30\n",
      "1269/1269 [==============================] - 1s 1ms/step - loss: 0.8270 - reactivity_loss: 0.1632 - deg_Mg_pH10_loss: 0.2100 - deg_Mg_50C_loss: 0.1723 - deg_pH10_loss: 0.1547 - deg_50C_loss: 0.1268 - reactivity_mean_squared_error: 0.1632 - deg_Mg_pH10_mean_squared_error: 0.2100 - deg_Mg_50C_mean_squared_error: 0.1723 - deg_pH10_mean_squared_error: 0.1547 - deg_50C_mean_squared_error: 0.1268 - val_loss: 0.8309 - val_reactivity_loss: 0.1663 - val_deg_Mg_pH10_loss: 0.2105 - val_deg_Mg_50C_loss: 0.1710 - val_deg_pH10_loss: 0.1542 - val_deg_50C_loss: 0.1288 - val_reactivity_mean_squared_error: 0.1663 - val_deg_Mg_pH10_mean_squared_error: 0.2105 - val_deg_Mg_50C_mean_squared_error: 0.1710 - val_deg_pH10_mean_squared_error: 0.1542 - val_deg_50C_mean_squared_error: 0.1288\n",
      "Epoch 5/30\n",
      "1269/1269 [==============================] - 1s 701us/step - loss: 0.8230 - reactivity_loss: 0.1626 - deg_Mg_pH10_loss: 0.2093 - deg_Mg_50C_loss: 0.1716 - deg_pH10_loss: 0.1536 - deg_50C_loss: 0.1258 - reactivity_mean_squared_error: 0.1626 - deg_Mg_pH10_mean_squared_error: 0.2093 - deg_Mg_50C_mean_squared_error: 0.1716 - deg_pH10_mean_squared_error: 0.1536 - deg_50C_mean_squared_error: 0.1258 - val_loss: 0.8269 - val_reactivity_loss: 0.1657 - val_deg_Mg_pH10_loss: 0.2100 - val_deg_Mg_50C_loss: 0.1702 - val_deg_pH10_loss: 0.1531 - val_deg_50C_loss: 0.1279 - val_reactivity_mean_squared_error: 0.1657 - val_deg_Mg_pH10_mean_squared_error: 0.2100 - val_deg_Mg_50C_mean_squared_error: 0.1702 - val_deg_pH10_mean_squared_error: 0.1531 - val_deg_50C_mean_squared_error: 0.1279\n",
      "Epoch 6/30\n",
      "1269/1269 [==============================] - 1s 686us/step - loss: 0.8208 - reactivity_loss: 0.1625 - deg_Mg_pH10_loss: 0.2090 - deg_Mg_50C_loss: 0.1710 - deg_pH10_loss: 0.1531 - deg_50C_loss: 0.1251 - reactivity_mean_squared_error: 0.1625 - deg_Mg_pH10_mean_squared_error: 0.2090 - deg_Mg_50C_mean_squared_error: 0.1710 - deg_pH10_mean_squared_error: 0.1531 - deg_50C_mean_squared_error: 0.1251 - val_loss: 0.8233 - val_reactivity_loss: 0.1652 - val_deg_Mg_pH10_loss: 0.2092 - val_deg_Mg_50C_loss: 0.1695 - val_deg_pH10_loss: 0.1525 - val_deg_50C_loss: 0.1268 - val_reactivity_mean_squared_error: 0.1652 - val_deg_Mg_pH10_mean_squared_error: 0.2092 - val_deg_Mg_50C_mean_squared_error: 0.1695 - val_deg_pH10_mean_squared_error: 0.1525 - val_deg_50C_mean_squared_error: 0.1268\n",
      "Epoch 7/30\n",
      "1269/1269 [==============================] - 1s 662us/step - loss: 0.8184 - reactivity_loss: 0.1623 - deg_Mg_pH10_loss: 0.2085 - deg_Mg_50C_loss: 0.1705 - deg_pH10_loss: 0.1524 - deg_50C_loss: 0.1247 - reactivity_mean_squared_error: 0.1623 - deg_Mg_pH10_mean_squared_error: 0.2085 - deg_Mg_50C_mean_squared_error: 0.1705 - deg_pH10_mean_squared_error: 0.1524 - deg_50C_mean_squared_error: 0.1247 - val_loss: 0.8235 - val_reactivity_loss: 0.1653 - val_deg_Mg_pH10_loss: 0.2094 - val_deg_Mg_50C_loss: 0.1695 - val_deg_pH10_loss: 0.1525 - val_deg_50C_loss: 0.1268 - val_reactivity_mean_squared_error: 0.1653 - val_deg_Mg_pH10_mean_squared_error: 0.2094 - val_deg_Mg_50C_mean_squared_error: 0.1695 - val_deg_pH10_mean_squared_error: 0.1525 - val_deg_50C_mean_squared_error: 0.1268\n",
      "Epoch 8/30\n",
      "1269/1269 [==============================] - 1s 654us/step - loss: 0.8164 - reactivity_loss: 0.1617 - deg_Mg_pH10_loss: 0.2083 - deg_Mg_50C_loss: 0.1702 - deg_pH10_loss: 0.1521 - deg_50C_loss: 0.1242 - reactivity_mean_squared_error: 0.1617 - deg_Mg_pH10_mean_squared_error: 0.2083 - deg_Mg_50C_mean_squared_error: 0.1702 - deg_pH10_mean_squared_error: 0.1521 - deg_50C_mean_squared_error: 0.1242 - val_loss: 0.8210 - val_reactivity_loss: 0.1648 - val_deg_Mg_pH10_loss: 0.2092 - val_deg_Mg_50C_loss: 0.1690 - val_deg_pH10_loss: 0.1520 - val_deg_50C_loss: 0.1260 - val_reactivity_mean_squared_error: 0.1648 - val_deg_Mg_pH10_mean_squared_error: 0.2092 - val_deg_Mg_50C_mean_squared_error: 0.1690 - val_deg_pH10_mean_squared_error: 0.1520 - val_deg_50C_mean_squared_error: 0.1260\n",
      "Epoch 9/30\n",
      "1269/1269 [==============================] - 1s 670us/step - loss: 0.8145 - reactivity_loss: 0.1615 - deg_Mg_pH10_loss: 0.2080 - deg_Mg_50C_loss: 0.1696 - deg_pH10_loss: 0.1517 - deg_50C_loss: 0.1237 - reactivity_mean_squared_error: 0.1615 - deg_Mg_pH10_mean_squared_error: 0.2080 - deg_Mg_50C_mean_squared_error: 0.1696 - deg_pH10_mean_squared_error: 0.1517 - deg_50C_mean_squared_error: 0.1237 - val_loss: 0.8212 - val_reactivity_loss: 0.1645 - val_deg_Mg_pH10_loss: 0.2093 - val_deg_Mg_50C_loss: 0.1695 - val_deg_pH10_loss: 0.1516 - val_deg_50C_loss: 0.1263 - val_reactivity_mean_squared_error: 0.1645 - val_deg_Mg_pH10_mean_squared_error: 0.2093 - val_deg_Mg_50C_mean_squared_error: 0.1695 - val_deg_pH10_mean_squared_error: 0.1516 - val_deg_50C_mean_squared_error: 0.1263\n",
      "Epoch 10/30\n",
      "1269/1269 [==============================] - 1s 670us/step - loss: 0.8121 - reactivity_loss: 0.1610 - deg_Mg_pH10_loss: 0.2075 - deg_Mg_50C_loss: 0.1692 - deg_pH10_loss: 0.1512 - deg_50C_loss: 0.1232 - reactivity_mean_squared_error: 0.1610 - deg_Mg_pH10_mean_squared_error: 0.2075 - deg_Mg_50C_mean_squared_error: 0.1692 - deg_pH10_mean_squared_error: 0.1512 - deg_50C_mean_squared_error: 0.1232 - val_loss: 0.8156 - val_reactivity_loss: 0.1635 - val_deg_Mg_pH10_loss: 0.2080 - val_deg_Mg_50C_loss: 0.1678 - val_deg_pH10_loss: 0.1509 - val_deg_50C_loss: 0.1253 - val_reactivity_mean_squared_error: 0.1635 - val_deg_Mg_pH10_mean_squared_error: 0.2080 - val_deg_Mg_50C_mean_squared_error: 0.1678 - val_deg_pH10_mean_squared_error: 0.1509 - val_deg_50C_mean_squared_error: 0.1253\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1269/1269 [==============================] - 1s 615us/step - loss: 0.8107 - reactivity_loss: 0.1606 - deg_Mg_pH10_loss: 0.2073 - deg_Mg_50C_loss: 0.1689 - deg_pH10_loss: 0.1510 - deg_50C_loss: 0.1229 - reactivity_mean_squared_error: 0.1606 - deg_Mg_pH10_mean_squared_error: 0.2073 - deg_Mg_50C_mean_squared_error: 0.1689 - deg_pH10_mean_squared_error: 0.1510 - deg_50C_mean_squared_error: 0.1229 - val_loss: 0.8145 - val_reactivity_loss: 0.1634 - val_deg_Mg_pH10_loss: 0.2080 - val_deg_Mg_50C_loss: 0.1676 - val_deg_pH10_loss: 0.1508 - val_deg_50C_loss: 0.1246 - val_reactivity_mean_squared_error: 0.1634 - val_deg_Mg_pH10_mean_squared_error: 0.2080 - val_deg_Mg_50C_mean_squared_error: 0.1676 - val_deg_pH10_mean_squared_error: 0.1508 - val_deg_50C_mean_squared_error: 0.1246\n",
      "Epoch 12/30\n",
      "1269/1269 [==============================] - 1s 599us/step - loss: 0.8086 - reactivity_loss: 0.1603 - deg_Mg_pH10_loss: 0.2069 - deg_Mg_50C_loss: 0.1684 - deg_pH10_loss: 0.1506 - deg_50C_loss: 0.1224 - reactivity_mean_squared_error: 0.1603 - deg_Mg_pH10_mean_squared_error: 0.2069 - deg_Mg_50C_mean_squared_error: 0.1684 - deg_pH10_mean_squared_error: 0.1506 - deg_50C_mean_squared_error: 0.1224 - val_loss: 0.8158 - val_reactivity_loss: 0.1635 - val_deg_Mg_pH10_loss: 0.2085 - val_deg_Mg_50C_loss: 0.1680 - val_deg_pH10_loss: 0.1510 - val_deg_50C_loss: 0.1248 - val_reactivity_mean_squared_error: 0.1635 - val_deg_Mg_pH10_mean_squared_error: 0.2085 - val_deg_Mg_50C_mean_squared_error: 0.1680 - val_deg_pH10_mean_squared_error: 0.1510 - val_deg_50C_mean_squared_error: 0.1248\n",
      "Epoch 13/30\n",
      "1269/1269 [==============================] - 1s 607us/step - loss: 0.8066 - reactivity_loss: 0.1599 - deg_Mg_pH10_loss: 0.2065 - deg_Mg_50C_loss: 0.1680 - deg_pH10_loss: 0.1502 - deg_50C_loss: 0.1220 - reactivity_mean_squared_error: 0.1599 - deg_Mg_pH10_mean_squared_error: 0.2065 - deg_Mg_50C_mean_squared_error: 0.1680 - deg_pH10_mean_squared_error: 0.1502 - deg_50C_mean_squared_error: 0.1220 - val_loss: 0.8118 - val_reactivity_loss: 0.1628 - val_deg_Mg_pH10_loss: 0.2077 - val_deg_Mg_50C_loss: 0.1672 - val_deg_pH10_loss: 0.1501 - val_deg_50C_loss: 0.1239 - val_reactivity_mean_squared_error: 0.1628 - val_deg_Mg_pH10_mean_squared_error: 0.2077 - val_deg_Mg_50C_mean_squared_error: 0.1672 - val_deg_pH10_mean_squared_error: 0.1501 - val_deg_50C_mean_squared_error: 0.1239\n",
      "Epoch 14/30\n",
      "1269/1269 [==============================] - 1s 686us/step - loss: 0.8053 - reactivity_loss: 0.1597 - deg_Mg_pH10_loss: 0.2063 - deg_Mg_50C_loss: 0.1677 - deg_pH10_loss: 0.1499 - deg_50C_loss: 0.1216 - reactivity_mean_squared_error: 0.1597 - deg_Mg_pH10_mean_squared_error: 0.2063 - deg_Mg_50C_mean_squared_error: 0.1677 - deg_pH10_mean_squared_error: 0.1499 - deg_50C_mean_squared_error: 0.1216 - val_loss: 0.8104 - val_reactivity_loss: 0.1627 - val_deg_Mg_pH10_loss: 0.2071 - val_deg_Mg_50C_loss: 0.1669 - val_deg_pH10_loss: 0.1498 - val_deg_50C_loss: 0.1240 - val_reactivity_mean_squared_error: 0.1627 - val_deg_Mg_pH10_mean_squared_error: 0.2071 - val_deg_Mg_50C_mean_squared_error: 0.1669 - val_deg_pH10_mean_squared_error: 0.1498 - val_deg_50C_mean_squared_error: 0.1240\n",
      "Epoch 15/30\n",
      "1269/1269 [==============================] - 1s 717us/step - loss: 0.8025 - reactivity_loss: 0.1592 - deg_Mg_pH10_loss: 0.2057 - deg_Mg_50C_loss: 0.1671 - deg_pH10_loss: 0.1495 - deg_50C_loss: 0.1210 - reactivity_mean_squared_error: 0.1592 - deg_Mg_pH10_mean_squared_error: 0.2057 - deg_Mg_50C_mean_squared_error: 0.1671 - deg_pH10_mean_squared_error: 0.1495 - deg_50C_mean_squared_error: 0.1210 - val_loss: 0.8082 - val_reactivity_loss: 0.1618 - val_deg_Mg_pH10_loss: 0.2069 - val_deg_Mg_50C_loss: 0.1665 - val_deg_pH10_loss: 0.1497 - val_deg_50C_loss: 0.1233 - val_reactivity_mean_squared_error: 0.1618 - val_deg_Mg_pH10_mean_squared_error: 0.2069 - val_deg_Mg_50C_mean_squared_error: 0.1665 - val_deg_pH10_mean_squared_error: 0.1497 - val_deg_50C_mean_squared_error: 0.1233\n",
      "Epoch 16/30\n",
      "1269/1269 [==============================] - 1s 709us/step - loss: 0.8002 - reactivity_loss: 0.1586 - deg_Mg_pH10_loss: 0.2054 - deg_Mg_50C_loss: 0.1665 - deg_pH10_loss: 0.1491 - deg_50C_loss: 0.1205 - reactivity_mean_squared_error: 0.1586 - deg_Mg_pH10_mean_squared_error: 0.2054 - deg_Mg_50C_mean_squared_error: 0.1665 - deg_pH10_mean_squared_error: 0.1491 - deg_50C_mean_squared_error: 0.1205 - val_loss: 0.8069 - val_reactivity_loss: 0.1616 - val_deg_Mg_pH10_loss: 0.2071 - val_deg_Mg_50C_loss: 0.1659 - val_deg_pH10_loss: 0.1494 - val_deg_50C_loss: 0.1229 - val_reactivity_mean_squared_error: 0.1616 - val_deg_Mg_pH10_mean_squared_error: 0.2071 - val_deg_Mg_50C_mean_squared_error: 0.1659 - val_deg_pH10_mean_squared_error: 0.1494 - val_deg_50C_mean_squared_error: 0.1229\n",
      "Epoch 17/30\n",
      "1269/1269 [==============================] - 1s 709us/step - loss: 0.7980 - reactivity_loss: 0.1581 - deg_Mg_pH10_loss: 0.2049 - deg_Mg_50C_loss: 0.1660 - deg_pH10_loss: 0.1488 - deg_50C_loss: 0.1202 - reactivity_mean_squared_error: 0.1581 - deg_Mg_pH10_mean_squared_error: 0.2049 - deg_Mg_50C_mean_squared_error: 0.1660 - deg_pH10_mean_squared_error: 0.1488 - deg_50C_mean_squared_error: 0.1202 - val_loss: 0.8043 - val_reactivity_loss: 0.1612 - val_deg_Mg_pH10_loss: 0.2062 - val_deg_Mg_50C_loss: 0.1654 - val_deg_pH10_loss: 0.1489 - val_deg_50C_loss: 0.1226 - val_reactivity_mean_squared_error: 0.1612 - val_deg_Mg_pH10_mean_squared_error: 0.2062 - val_deg_Mg_50C_mean_squared_error: 0.1654 - val_deg_pH10_mean_squared_error: 0.1489 - val_deg_50C_mean_squared_error: 0.1226\n",
      "Epoch 18/30\n",
      "1269/1269 [==============================] - 1s 749us/step - loss: 0.7952 - reactivity_loss: 0.1576 - deg_Mg_pH10_loss: 0.2044 - deg_Mg_50C_loss: 0.1654 - deg_pH10_loss: 0.1484 - deg_50C_loss: 0.1195 - reactivity_mean_squared_error: 0.1576 - deg_Mg_pH10_mean_squared_error: 0.2044 - deg_Mg_50C_mean_squared_error: 0.1654 - deg_pH10_mean_squared_error: 0.1484 - deg_50C_mean_squared_error: 0.1195 - val_loss: 0.8027 - val_reactivity_loss: 0.1608 - val_deg_Mg_pH10_loss: 0.2059 - val_deg_Mg_50C_loss: 0.1651 - val_deg_pH10_loss: 0.1488 - val_deg_50C_loss: 0.1221 - val_reactivity_mean_squared_error: 0.1608 - val_deg_Mg_pH10_mean_squared_error: 0.2059 - val_deg_Mg_50C_mean_squared_error: 0.1651 - val_deg_pH10_mean_squared_error: 0.1488 - val_deg_50C_mean_squared_error: 0.1221\n",
      "Epoch 19/30\n",
      "1269/1269 [==============================] - 1s 670us/step - loss: 0.7932 - reactivity_loss: 0.1570 - deg_Mg_pH10_loss: 0.2041 - deg_Mg_50C_loss: 0.1650 - deg_pH10_loss: 0.1480 - deg_50C_loss: 0.1191 - reactivity_mean_squared_error: 0.1570 - deg_Mg_pH10_mean_squared_error: 0.2041 - deg_Mg_50C_mean_squared_error: 0.1650 - deg_pH10_mean_squared_error: 0.1480 - deg_50C_mean_squared_error: 0.1191 - val_loss: 0.8013 - val_reactivity_loss: 0.1607 - val_deg_Mg_pH10_loss: 0.2053 - val_deg_Mg_50C_loss: 0.1647 - val_deg_pH10_loss: 0.1487 - val_deg_50C_loss: 0.1219 - val_reactivity_mean_squared_error: 0.1607 - val_deg_Mg_pH10_mean_squared_error: 0.2053 - val_deg_Mg_50C_mean_squared_error: 0.1647 - val_deg_pH10_mean_squared_error: 0.1487 - val_deg_50C_mean_squared_error: 0.1219\n",
      "Epoch 20/30\n",
      "1269/1269 [==============================] - 1s 638us/step - loss: 0.7906 - reactivity_loss: 0.1566 - deg_Mg_pH10_loss: 0.2035 - deg_Mg_50C_loss: 0.1643 - deg_pH10_loss: 0.1475 - deg_50C_loss: 0.1186 - reactivity_mean_squared_error: 0.1566 - deg_Mg_pH10_mean_squared_error: 0.2035 - deg_Mg_50C_mean_squared_error: 0.1643 - deg_pH10_mean_squared_error: 0.1475 - deg_50C_mean_squared_error: 0.1186 - val_loss: 0.7989 - val_reactivity_loss: 0.1603 - val_deg_Mg_pH10_loss: 0.2048 - val_deg_Mg_50C_loss: 0.1640 - val_deg_pH10_loss: 0.1482 - val_deg_50C_loss: 0.1216 - val_reactivity_mean_squared_error: 0.1603 - val_deg_Mg_pH10_mean_squared_error: 0.2048 - val_deg_Mg_50C_mean_squared_error: 0.1640 - val_deg_pH10_mean_squared_error: 0.1482 - val_deg_50C_mean_squared_error: 0.1216\n",
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1269/1269 [==============================] - 1s 693us/step - loss: 0.7885 - reactivity_loss: 0.1561 - deg_Mg_pH10_loss: 0.2031 - deg_Mg_50C_loss: 0.1639 - deg_pH10_loss: 0.1472 - deg_50C_loss: 0.1182 - reactivity_mean_squared_error: 0.1561 - deg_Mg_pH10_mean_squared_error: 0.2031 - deg_Mg_50C_mean_squared_error: 0.1639 - deg_pH10_mean_squared_error: 0.1472 - deg_50C_mean_squared_error: 0.1182 - val_loss: 0.7986 - val_reactivity_loss: 0.1599 - val_deg_Mg_pH10_loss: 0.2046 - val_deg_Mg_50C_loss: 0.1643 - val_deg_pH10_loss: 0.1480 - val_deg_50C_loss: 0.1218 - val_reactivity_mean_squared_error: 0.1599 - val_deg_Mg_pH10_mean_squared_error: 0.2046 - val_deg_Mg_50C_mean_squared_error: 0.1643 - val_deg_pH10_mean_squared_error: 0.1480 - val_deg_50C_mean_squared_error: 0.1218\n",
      "Epoch 22/30\n",
      "1269/1269 [==============================] - 1s 930us/step - loss: 0.7861 - reactivity_loss: 0.1555 - deg_Mg_pH10_loss: 0.2027 - deg_Mg_50C_loss: 0.1634 - deg_pH10_loss: 0.1468 - deg_50C_loss: 0.1177 - reactivity_mean_squared_error: 0.1555 - deg_Mg_pH10_mean_squared_error: 0.2027 - deg_Mg_50C_mean_squared_error: 0.1634 - deg_pH10_mean_squared_error: 0.1468 - deg_50C_mean_squared_error: 0.1177 - val_loss: 0.7948 - val_reactivity_loss: 0.1594 - val_deg_Mg_pH10_loss: 0.2037 - val_deg_Mg_50C_loss: 0.1634 - val_deg_pH10_loss: 0.1474 - val_deg_50C_loss: 0.1209 - val_reactivity_mean_squared_error: 0.1594 - val_deg_Mg_pH10_mean_squared_error: 0.2037 - val_deg_Mg_50C_mean_squared_error: 0.1634 - val_deg_pH10_mean_squared_error: 0.1474 - val_deg_50C_mean_squared_error: 0.1209\n",
      "Epoch 23/30\n",
      "1269/1269 [==============================] - 1s 662us/step - loss: 0.7839 - reactivity_loss: 0.1551 - deg_Mg_pH10_loss: 0.2022 - deg_Mg_50C_loss: 0.1629 - deg_pH10_loss: 0.1465 - deg_50C_loss: 0.1173 - reactivity_mean_squared_error: 0.1551 - deg_Mg_pH10_mean_squared_error: 0.2022 - deg_Mg_50C_mean_squared_error: 0.1629 - deg_pH10_mean_squared_error: 0.1465 - deg_50C_mean_squared_error: 0.1173 - val_loss: 0.7935 - val_reactivity_loss: 0.1591 - val_deg_Mg_pH10_loss: 0.2036 - val_deg_Mg_50C_loss: 0.1628 - val_deg_pH10_loss: 0.1474 - val_deg_50C_loss: 0.1207 - val_reactivity_mean_squared_error: 0.1591 - val_deg_Mg_pH10_mean_squared_error: 0.2036 - val_deg_Mg_50C_mean_squared_error: 0.1628 - val_deg_pH10_mean_squared_error: 0.1474 - val_deg_50C_mean_squared_error: 0.1207\n",
      "Epoch 24/30\n",
      "1269/1269 [==============================] - 1s 615us/step - loss: 0.7817 - reactivity_loss: 0.1546 - deg_Mg_pH10_loss: 0.2016 - deg_Mg_50C_loss: 0.1623 - deg_pH10_loss: 0.1462 - deg_50C_loss: 0.1170 - reactivity_mean_squared_error: 0.1546 - deg_Mg_pH10_mean_squared_error: 0.2016 - deg_Mg_50C_mean_squared_error: 0.1623 - deg_pH10_mean_squared_error: 0.1462 - deg_50C_mean_squared_error: 0.1170 - val_loss: 0.7914 - val_reactivity_loss: 0.1585 - val_deg_Mg_pH10_loss: 0.2031 - val_deg_Mg_50C_loss: 0.1628 - val_deg_pH10_loss: 0.1468 - val_deg_50C_loss: 0.1202 - val_reactivity_mean_squared_error: 0.1585 - val_deg_Mg_pH10_mean_squared_error: 0.2031 - val_deg_Mg_50C_mean_squared_error: 0.1628 - val_deg_pH10_mean_squared_error: 0.1468 - val_deg_50C_mean_squared_error: 0.1202\n",
      "Epoch 25/30\n",
      "1269/1269 [==============================] - 1s 638us/step - loss: 0.7794 - reactivity_loss: 0.1539 - deg_Mg_pH10_loss: 0.2012 - deg_Mg_50C_loss: 0.1619 - deg_pH10_loss: 0.1457 - deg_50C_loss: 0.1167 - reactivity_mean_squared_error: 0.1539 - deg_Mg_pH10_mean_squared_error: 0.2012 - deg_Mg_50C_mean_squared_error: 0.1619 - deg_pH10_mean_squared_error: 0.1457 - deg_50C_mean_squared_error: 0.1167 - val_loss: 0.7915 - val_reactivity_loss: 0.1588 - val_deg_Mg_pH10_loss: 0.2030 - val_deg_Mg_50C_loss: 0.1625 - val_deg_pH10_loss: 0.1467 - val_deg_50C_loss: 0.1205 - val_reactivity_mean_squared_error: 0.1588 - val_deg_Mg_pH10_mean_squared_error: 0.2030 - val_deg_Mg_50C_mean_squared_error: 0.1625 - val_deg_pH10_mean_squared_error: 0.1467 - val_deg_50C_mean_squared_error: 0.1205\n",
      "Epoch 26/30\n",
      "1269/1269 [==============================] - 1s 615us/step - loss: 0.7771 - reactivity_loss: 0.1535 - deg_Mg_pH10_loss: 0.2007 - deg_Mg_50C_loss: 0.1613 - deg_pH10_loss: 0.1454 - deg_50C_loss: 0.1162 - reactivity_mean_squared_error: 0.1535 - deg_Mg_pH10_mean_squared_error: 0.2007 - deg_Mg_50C_mean_squared_error: 0.1613 - deg_pH10_mean_squared_error: 0.1454 - deg_50C_mean_squared_error: 0.1162 - val_loss: 0.7908 - val_reactivity_loss: 0.1581 - val_deg_Mg_pH10_loss: 0.2031 - val_deg_Mg_50C_loss: 0.1626 - val_deg_pH10_loss: 0.1468 - val_deg_50C_loss: 0.1202 - val_reactivity_mean_squared_error: 0.1581 - val_deg_Mg_pH10_mean_squared_error: 0.2031 - val_deg_Mg_50C_mean_squared_error: 0.1626 - val_deg_pH10_mean_squared_error: 0.1468 - val_deg_50C_mean_squared_error: 0.1202\n",
      "Epoch 27/30\n",
      "1269/1269 [==============================] - 1s 615us/step - loss: 0.7753 - reactivity_loss: 0.1529 - deg_Mg_pH10_loss: 0.2003 - deg_Mg_50C_loss: 0.1610 - deg_pH10_loss: 0.1451 - deg_50C_loss: 0.1159 - reactivity_mean_squared_error: 0.1529 - deg_Mg_pH10_mean_squared_error: 0.2003 - deg_Mg_50C_mean_squared_error: 0.1610 - deg_pH10_mean_squared_error: 0.1451 - deg_50C_mean_squared_error: 0.1159 - val_loss: 0.7887 - val_reactivity_loss: 0.1576 - val_deg_Mg_pH10_loss: 0.2025 - val_deg_Mg_50C_loss: 0.1620 - val_deg_pH10_loss: 0.1464 - val_deg_50C_loss: 0.1202 - val_reactivity_mean_squared_error: 0.1576 - val_deg_Mg_pH10_mean_squared_error: 0.2025 - val_deg_Mg_50C_mean_squared_error: 0.1620 - val_deg_pH10_mean_squared_error: 0.1464 - val_deg_50C_mean_squared_error: 0.1202\n",
      "Epoch 28/30\n",
      "1269/1269 [==============================] - 1s 623us/step - loss: 0.7732 - reactivity_loss: 0.1524 - deg_Mg_pH10_loss: 0.1998 - deg_Mg_50C_loss: 0.1606 - deg_pH10_loss: 0.1447 - deg_50C_loss: 0.1157 - reactivity_mean_squared_error: 0.1524 - deg_Mg_pH10_mean_squared_error: 0.1998 - deg_Mg_50C_mean_squared_error: 0.1606 - deg_pH10_mean_squared_error: 0.1447 - deg_50C_mean_squared_error: 0.1157 - val_loss: 0.7877 - val_reactivity_loss: 0.1577 - val_deg_Mg_pH10_loss: 0.2022 - val_deg_Mg_50C_loss: 0.1618 - val_deg_pH10_loss: 0.1460 - val_deg_50C_loss: 0.1200 - val_reactivity_mean_squared_error: 0.1577 - val_deg_Mg_pH10_mean_squared_error: 0.2022 - val_deg_Mg_50C_mean_squared_error: 0.1618 - val_deg_pH10_mean_squared_error: 0.1460 - val_deg_50C_mean_squared_error: 0.1200\n",
      "Epoch 29/30\n",
      "1269/1269 [==============================] - 1s 630us/step - loss: 0.7726 - reactivity_loss: 0.1521 - deg_Mg_pH10_loss: 0.1995 - deg_Mg_50C_loss: 0.1605 - deg_pH10_loss: 0.1447 - deg_50C_loss: 0.1158 - reactivity_mean_squared_error: 0.1521 - deg_Mg_pH10_mean_squared_error: 0.1995 - deg_Mg_50C_mean_squared_error: 0.1605 - deg_pH10_mean_squared_error: 0.1447 - deg_50C_mean_squared_error: 0.1158 - val_loss: 0.7877 - val_reactivity_loss: 0.1574 - val_deg_Mg_pH10_loss: 0.2020 - val_deg_Mg_50C_loss: 0.1622 - val_deg_pH10_loss: 0.1462 - val_deg_50C_loss: 0.1199 - val_reactivity_mean_squared_error: 0.1574 - val_deg_Mg_pH10_mean_squared_error: 0.2020 - val_deg_Mg_50C_mean_squared_error: 0.1622 - val_deg_pH10_mean_squared_error: 0.1462 - val_deg_50C_mean_squared_error: 0.1199\n",
      "Epoch 30/30\n",
      "1269/1269 [==============================] - 1s 607us/step - loss: 0.7690 - reactivity_loss: 0.1513 - deg_Mg_pH10_loss: 0.1987 - deg_Mg_50C_loss: 0.1598 - deg_pH10_loss: 0.1441 - deg_50C_loss: 0.1150 - reactivity_mean_squared_error: 0.1513 - deg_Mg_pH10_mean_squared_error: 0.1987 - deg_Mg_50C_mean_squared_error: 0.1598 - deg_pH10_mean_squared_error: 0.1441 - deg_50C_mean_squared_error: 0.1150 - val_loss: 0.7842 - val_reactivity_loss: 0.1567 - val_deg_Mg_pH10_loss: 0.2014 - val_deg_Mg_50C_loss: 0.1610 - val_deg_pH10_loss: 0.1455 - val_deg_50C_loss: 0.1196 - val_reactivity_mean_squared_error: 0.1567 - val_deg_Mg_pH10_mean_squared_error: 0.2014 - val_deg_Mg_50C_mean_squared_error: 0.1610 - val_deg_pH10_mean_squared_error: 0.1455 - val_deg_50C_mean_squared_error: 0.1196\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xc013a20>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([inputs_simple[:,:,0:4], inputs_simple[:,:,4:7], inputs_simple[:,:,7:14]],\n",
    "          [expected_results[:,:,0], expected_results[:,:,1], expected_results[:,:,2],\n",
    "          expected_results[:,:,3], expected_results[:,:,4]], batch_size = 25, \n",
    "          epochs = 30, verbose = 1, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_simple[0,0,0:4]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Revoir donnees a predire**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
